[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis and Visualisation with R",
    "section": "",
    "text": "A core element of the AAU Information Studies degree is learning about data analysis and visualization. To teach you these skills, we use the statistical programming language R. Specifically, we will use the Tidyverse, an opinionated collection of R packages that share an underlying design philosophy, grammar, and data structures."
  },
  {
    "objectID": "index.html#about-this-website",
    "href": "index.html#about-this-website",
    "title": "Data Analysis and Visualisation with R",
    "section": "About this website",
    "text": "About this website\nAt AAU we use Moodle to inform you about the different modules, their content and distribute reading and exercise material. We will touch on R in various classes in two different modules Research Methods in Information Studies and User Studies and Information Behaviour. This can be confusing, that is why this website is thought to collect all R related teaching in one space and covers all aspects that happen in class. This means, this website is substituting the course slides. Additional material for e.g. preparation before class like reading material can be found on Moodle."
  },
  {
    "objectID": "index.html#r-and-rstudio-set-up",
    "href": "index.html#r-and-rstudio-set-up",
    "title": "Data Analysis and Visualisation with R",
    "section": "R and RStudio Set-up",
    "text": "R and RStudio Set-up\nChester Ismay and Albert Kim, the authors of Moderndive an introductory book to Data Science using R and the Tidyverse, describe it like this: R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. You need to install both parts to get everything to work. You can find the links to download both from Posit’s website. A detailed guide can also be found on the Moderndive website."
  },
  {
    "objectID": "index.html#some-general-tips",
    "href": "index.html#some-general-tips",
    "title": "Data Analysis and Visualisation with R",
    "section": "Some general tips",
    "text": "Some general tips\n\nAs a beginner it is always good to take a \"copy - paste - adpat\" approach to coding. Copy code from when you solved the same/similar problems, paste it and adapt it to the current situation (e.g. change the data frame and variable name).This is - especially at the beginning - easier than writing everything from scratch.\nDon’t despair if your code throws an error. You can:\n\nPut the error message in a search engine and look at the results. Most likely someone had the same issue before and asked about it on Stackoverflow.\nUse ChatGPT to come up with a suggestion on how to solve the problem.\n\nYou want your object (e.g. data.frames, vectors or functions) to be descriptive, so you’ll need a convention for multiple words. Hadley Wickham recommends snake_case where you separate lowercase words with _. E.g.:\n\npenguins_data\nusasbility_test_results_1\nparticipant_ids\ncalc_sus()\n\n… to be continued()"
  },
  {
    "objectID": "content/Session1.html",
    "href": "content/Session1.html",
    "title": "Part1:Collection, cleaning and transformation",
    "section": "",
    "text": "In preparation for the first session, please work yourself through the intro_new.R file. You can download the file from Moodle or copy paste the parts from here, and put it into a new file. You can create a new file in RStudio via File -&gt; New file -&gt; R Script.\n\n\nShow/Hide Code\n#######\n## Introduction to programming // R 101\n######\n\n\n#### \n# Watch the following videos that explain the main components of R\n# Functions: https://vimeo.com/220490105\n# -----------------------------------------\n# Arguments: https://vimeo.com/220490157\n#------------------------------------------\n# Objects: https://vimeo.com/220493412 \n# -----------------------------------------\n# Vectors: https://vimeo.com/220490316 \n# -----------------------------------------\n# Data Types: https://vimeo.com/220490241 \n\n\n#### \n# 1. Now try to solve the following tasks:\n\n# 1.1 Execute the following lines. Try to explain the differences between line 28, 30 and 31?\n5+4\na &lt;- 5\nb &lt;- 4\nc &lt;- a - b\nd &lt;- c(a,b)\nsum(a,b)\nmax(a,b)\ne &lt;- sum(a,b)\nf &lt;- a + b \n\n\n\n# 1.2 Why does the following snippet return NA?\n# What does NA mean? (try to google for it)\n# What can you do to make it return a number? (look in the documentation for help)\nsum(1,2,3,7,NA)\n\n\n\n# 1.3 Investigate the following four vectors:\n# Use the function typeof() to investigate each vectors datatype\n# What is suprising about v4? Can you explain what happened?\n# How can you check whether 6 is part of v3?\n# Use length() to check whether v1 and v2 are of similar length?\nv1 &lt;- c('one','two','three','four')\nv2 &lt;- c('1','2','3','4')\nv3 &lt;- c(1,2,3,4,5)\nv4 &lt;- c(1,'two',3)\n\n\n\n#2.Investigate the built in data-set 'mtcars'. \n# Use str(mtcars) to answer the following questions:\n\n    # Which data type does the data-set have?\n    # How many variables and observartions does the data-set have?\n    # Call the help function for the data-set \n    # to find out about the meaning of the variables\n    # Select three variables of the data set and save them in a \n    # single new vector, one for each\n    # Can you select a single row of the data frame using base R only? \n    # Try to google/use stackoverflow for help!\n\n\n\n\n\n###########\n# Finally watch the video on packages in R\n# Packages: https://vimeo.com/220490447 \n\n# Install the package tidyverse and make it available for use\n\n# To check whether you were successful try to \n# run the following code snippet: \n\nggplot(data = diamonds) +\n     geom_bar(mapping = aes(x = cut))"
  },
  {
    "objectID": "content/Session1.html#r-basics-with-intro_new.r",
    "href": "content/Session1.html#r-basics-with-intro_new.r",
    "title": "Part1:Collection, cleaning and transformation",
    "section": "",
    "text": "In preparation for the first session, please work yourself through the intro_new.R file. You can download the file from Moodle or copy paste the parts from here, and put it into a new file. You can create a new file in RStudio via File -&gt; New file -&gt; R Script.\n\n\nShow/Hide Code\n#######\n## Introduction to programming // R 101\n######\n\n\n#### \n# Watch the following videos that explain the main components of R\n# Functions: https://vimeo.com/220490105\n# -----------------------------------------\n# Arguments: https://vimeo.com/220490157\n#------------------------------------------\n# Objects: https://vimeo.com/220493412 \n# -----------------------------------------\n# Vectors: https://vimeo.com/220490316 \n# -----------------------------------------\n# Data Types: https://vimeo.com/220490241 \n\n\n#### \n# 1. Now try to solve the following tasks:\n\n# 1.1 Execute the following lines. Try to explain the differences between line 28, 30 and 31?\n5+4\na &lt;- 5\nb &lt;- 4\nc &lt;- a - b\nd &lt;- c(a,b)\nsum(a,b)\nmax(a,b)\ne &lt;- sum(a,b)\nf &lt;- a + b \n\n\n\n# 1.2 Why does the following snippet return NA?\n# What does NA mean? (try to google for it)\n# What can you do to make it return a number? (look in the documentation for help)\nsum(1,2,3,7,NA)\n\n\n\n# 1.3 Investigate the following four vectors:\n# Use the function typeof() to investigate each vectors datatype\n# What is suprising about v4? Can you explain what happened?\n# How can you check whether 6 is part of v3?\n# Use length() to check whether v1 and v2 are of similar length?\nv1 &lt;- c('one','two','three','four')\nv2 &lt;- c('1','2','3','4')\nv3 &lt;- c(1,2,3,4,5)\nv4 &lt;- c(1,'two',3)\n\n\n\n#2.Investigate the built in data-set 'mtcars'. \n# Use str(mtcars) to answer the following questions:\n\n    # Which data type does the data-set have?\n    # How many variables and observartions does the data-set have?\n    # Call the help function for the data-set \n    # to find out about the meaning of the variables\n    # Select three variables of the data set and save them in a \n    # single new vector, one for each\n    # Can you select a single row of the data frame using base R only? \n    # Try to google/use stackoverflow for help!\n\n\n\n\n\n###########\n# Finally watch the video on packages in R\n# Packages: https://vimeo.com/220490447 \n\n# Install the package tidyverse and make it available for use\n\n# To check whether you were successful try to \n# run the following code snippet: \n\nggplot(data = diamonds) +\n     geom_bar(mapping = aes(x = cut))"
  },
  {
    "objectID": "content/Session1.html#intalling-and-loading-packages",
    "href": "content/Session1.html#intalling-and-loading-packages",
    "title": "Part1:Collection, cleaning and transformation",
    "section": "Intalling and loading packages",
    "text": "Intalling and loading packages\nBase R can easily be extended by additional functions, data and routines that are wrapped in so called packages. R has a large community that develops packages on a daily basis which makes the programming language so accessible and versatile. Packages can either be installed via the RStudio GUI or via the console/your R code. You use the function install.packages() and put in the name of the package. As mentioned earlier we will use the tidyverse. We also start with a packages that gives us access to a popular data set, the palmer penguins data. After installing the packages you also need to make them accessible. This you do by using the function require() or library(). Note that packages only need to be installed once. However, everytime you reopen your RStudio, you also need to make the package accessible again via either require() or library().\n\n\nShow/Hide Code\ninstall.packages(\"tidyverse\")\ninstall.packages(\"palmerpenguins\")\nrequire(tidyverse)\nrequire(palmerpenguins)\n\n\n\nLet them eat cake\nLet’s have a look at the penguins data and do a first little bar chart of the penguins.\n\n\nShow/Hide Code\n# We save the built-in dataset into a data.frame/tibble that lives in your environment.\npenguins_data&lt;-penguins\npenguins_data\n\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nShow/Hide Code\npenguins_data%&gt;%ggplot(aes(species))+geom_bar()\n\n\n\n\n\n\n\nImporting data from files\nThe tidyverse has a package called readr that is specifically dedicated to load various kinds of files, e.g. .csv, .tsv, excel and so on. You can also import data from databases (SQLite or no-sql like CouchDB). Let’s have a quick look. We will perform some exercises with the fake usability test data I mentioned in class. For this purpose please download the file usability_test_results.csv from Moodle.\n\n\nShow/Hide Code\nusability_test_results &lt;- read_csv(\"usability_test_results.csv\")\n\n\nRows: 30 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): participant_id, timestamp, age, gender, country_of_nationality, ed...\ndbl (11): trips_per_year, countries_visited, completion_task1, seq_task1, to...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "content/Session1.html#dplyr-basics",
    "href": "content/Session1.html#dplyr-basics",
    "title": "Part1:Collection, cleaning and transformation",
    "section": "Dplyr basics",
    "text": "Dplyr basics\nDplyr works with the pipe symbol %&gt;%. Usually you start with the data frame that you want to manipulate, followed by the first dplyr verb. E.g: penguins_data%&gt;%filter() or penguins_data%&gt;%select. You can chain the verbs as much as you want and create data manipulation pipelines. E.g: penguins_data%&gt;%filter(...)%&gt;%select(...). We will see more examples further below.\n\nFilter()\nNow we get to know the verbs that are part of dplyr. We start with the filter() function and the different logical operators e.g.AND, OR, NOT, is.na(). We will aim at answering the following questions:\n\nFind all penguins that were found on island Dream\nFind all penguins that are heavier than 4 kg\nFind all penguins that are female and heavier than 4 kg\nAre there more male or female penguins that are heavier than 4kg?\nFind all penguins where the sex is not missing (NA)\n\n\n\nShow/Hide Code\n# We start off by learning about filter()\n\n# We want the ones that lived on island Dream\npenguins_data%&gt;%filter(island=='Dream')%&gt;%view()\n\n# We want the ones heavier than 4kg\npenguins_data%&gt;%filter(body_mass_g&gt;4000)%&gt;%nrow()\n\n\n[1] 172\n\n\nShow/Hide Code\n# We ant to have all females heavier than 4000\npenguins_data%&gt;%filter(body_mass_g&gt;4000)%&gt;%\n                    filter(sex=='female')%&gt;%view()\n\n# another way is using only one filter\npenguins_data%&gt;%filter(body_mass_g&gt;4000,sex=='female')%&gt;%nrow()\n\n\n[1] 58\n\n\nShow/Hide Code\n# Are there more male penguins \npenguins_data%&gt;%filter(body_mass_g&gt;4000,sex=='male')%&gt;%nrow()\n\n\n[1] 109\n\n\nShow/Hide Code\n# We want to filter out the penguins with missing sex\npenguins_complete_sex&lt;-penguins_data%&gt;%filter(!is.na(sex))\n\n\nNow we perform some exercises with the usability_test_results.csv. We try to answer the following questions:\n\nFind all participants that are from Denmark\nFind all participants that successfully completed task 3\nFind all participants that have a bachelor and whose favorite country is Japan\nFind all participants whose favorite country is Germany or Italy\nAdvanced : Find all participants whose time on task2 #lies above the average for that task\n Advanced : Filter based on %in%: Exclude participants from United States, Canada Mexico.\n\n\n\nShow/Hide Code\n# Find all participants that are from Denmark\nusability_test_results%&gt;%filter(country_of_nationality=='Denmark')%&gt;%view()\n\n# Find all participants that successfully completed task 3\nusability_test_results%&gt;%filter(completion_task3==1)%&gt;%view()\n\n# Find all participants that have a bachelor and whose favorite country\n# is Japan\nusability_test_results%&gt;%filter(education=='Bachelor',\n                                favority_country=='Japan')%&gt;%view()\n\n# Find all participants whose favorite country is germany or italy\nusability_test_results%&gt;%\n        filter(favority_country=='Germany'|favority_country=='Italy')%&gt;%view()\n\n#Find all participants whose time on task2 \n#lies above the average for that task\n\nusability_test_results%&gt;%filter(mean(tot_task2)&lt;tot_task2)%&gt;%view()\n\n#Use base are style of writing to calculate an average\nmean(usability_test_results$tot_task2)\n\n\n[1] 44.83333\n\n\nShow/Hide Code\n# Show an example of how to use %in% to filter by values\n# of a vector\ncountries_to_filter&lt;-c('United States','Canada','Mexico')\n\nusability_test_results%&gt;%\n  filter(!country_of_nationality%in%countries_to_filter)%&gt;%\n      view()\n\n\n\n\nArrange()\nSorting your data can be important to get an overview of the data but also for certain processing tasks. You can sort using the arrange() function. Per default arrange sorts ascending i.e. from lowest to highest. Use the desc() inside arrange to sort from high to low.\n\n\nShow/Hide Code\n# Now we want to look at sorting data with arrange()\n\npenguins_data%&gt;%arrange(flipper_length_mm)%&gt;%view()\n\npenguins_data%&gt;%arrange(desc(body_mass_g))%&gt;%view()\n\npenguins_data%&gt;%arrange(-body_mass_g)%&gt;%view()\n\npenguins_data%&gt;%arrange(bill_length_mm,bill_depth_mm)%&gt;%view()\n\n\n# Two exercises with the usability_test_data\n\n# Sort the test data based on the country of origin of the participants \n\n# Sort the test data based on subjective task difficulty (seq_task1)\nusability_test_results%&gt;%arrange(-seq_task1,-seq_task2,-seq_task3)%&gt;%view()\n\n\n\n\nSelect()\nIt is often the case that you only need a subset of the data for further processing or visualisation. In these situations the select() function becomes handy, as it allows us to select only the needed columns or variables from the data.frame. Select() has many different ways of how it can be used. Here it is worth to look at the documentation to get an overview of what the options are.\n\n\nShow/Hide Code\n# Let's now look into selecting different columnns\n# we use the select() function for that \n\n# by column name\npenguins_data%&gt;%select(species,island,body_mass_g)\n\n\n# A tibble: 344 × 3\n   species island    body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;int&gt;\n 1 Adelie  Torgersen        3750\n 2 Adelie  Torgersen        3800\n 3 Adelie  Torgersen        3250\n 4 Adelie  Torgersen          NA\n 5 Adelie  Torgersen        3450\n 6 Adelie  Torgersen        3650\n 7 Adelie  Torgersen        3625\n 8 Adelie  Torgersen        4675\n 9 Adelie  Torgersen        3475\n10 Adelie  Torgersen        4250\n# ℹ 334 more rows\n\n\nShow/Hide Code\n# select by range\n\npenguins_data%&gt;%select(bill_length_mm:body_mass_g)%&gt;%view()\n\n# select by column number\npenguins_data%&gt;%select(1,7)%&gt;%view()\n\n# select ALL columns but an exception \npenguins_data%&gt;%select(-island)%&gt;%view()\n  \n# you can use function within select\n# for example starts_with(), ends_with(), contains()\n\npenguins_data%&gt;%select(species,starts_with('bill_'))%&gt;%view()\n\n\nNow it is on you again, to perform some exercises with the usability_test_results.csv. Try do do the following:\n\nCreate a data frame that only contains the columns: participant_id, age, and trips per year.\nCreate a data frame that contains column 2 and tot_task3.\nCreate a data frame that contains participant_id and all columns that are related to task1.\n\n\n\nShow/Hide Code\n#Select participant_id, age and trips per year\nusability_test_results%&gt;%select(participant_id,age,trips_per_year)\n\n\n# A tibble: 30 × 3\n   participant_id age   trips_per_year\n   &lt;chr&gt;          &lt;chr&gt;          &lt;dbl&gt;\n 1 id_1           22-29             15\n 2 id_2           22-29             10\n 3 id_3           51-64              0\n 4 id_4           19-21              5\n 5 id_5           30-40              3\n 6 id_6           19-21              5\n 7 id_7           51-64              4\n 8 id_8           22-29              2\n 9 id_9           22-29             13\n10 id_10          22-29              4\n# ℹ 20 more rows\n\n\nShow/Hide Code\n#Select the second and the last column\nusability_test_results%&gt;%select(2,tot_task3)%&gt;%view()\n\n#Select participant_id and all column related to task1\nusability_test_results%&gt;%select(participant_id,\n                            contains(\"task1\"))%&gt;%view()\n\n# Let's do some renaming of column names \n\npenguins_data%&gt;%rename(weight=body_mass_g)%&gt;%view()\n\n\n\n\nData manipulation pipelines\nYou can combine the verbs in any way you want and chain them one after another. E.g. filter %&gt;% filter %&gt;% select %&gt;% filter is possible. But be aware to only filter on columns that still exist!\n\n\nShow/Hide Code\npenguins_new&lt;-penguins_data%&gt;%filter(island=='Dream'|island=='Torgersen')%&gt;%\n                                filter(sex=='male')%&gt;%\n                                select(species,body_mass_g)\n\n# or an example with the usability_test_results \n\nusability_test_results%&gt;%filter(education=='Bachelor')%&gt;%\n                          filter(completion_task3==1)%&gt;%\n                            select(participant_id)\n\n\n# A tibble: 9 × 1\n  participant_id\n  &lt;chr&gt;         \n1 id_3          \n2 id_4          \n3 id_8          \n4 id_9          \n5 id_11         \n6 id_23         \n7 id_24         \n8 id_25         \n9 id_27         \n\n\n\n\nWrite data to file\nFinally, we want to write a data to file, so we can reload it later on. We have two options: * Write the data to an .Rdata file, R’s customs binary format, using write_rds(). This file can then be loaded via read_rds(). * Write to a .csv file - increased interoperability and better for sharing with others. readr has a specific function that let’s you create .csv files that are easy to open in excel: write_excel_csv().\n\n\nShow/Hide Code\npenguins_new&lt;-penguins_data%&gt;%filter(island=='Dream'|island=='Torgersen')%&gt;%\n                                filter(sex=='male')%&gt;%\n                                select(species,body_mass_g)\n\nwrite_rds(penguins_new,'penguins_new.rds')\n\n# Let's use the usability_test_results \n# We want to get all participants in the age group 22-29\n# We want that they completed task 2 \n# And then we want all columns related to that task (task2)\nusability_new&lt;-usability_test_results%&gt;%\n            filter(age=='22-29',completion_task2=='1')%&gt;%\n                select(contains('task2'))\n\nwrite_excel_csv(x = usability_new,'usablity_new.csv')"
  },
  {
    "objectID": "content/Session2.html",
    "href": "content/Session2.html",
    "title": "Part2:Collection, cleaning and transformation",
    "section": "",
    "text": "Now we look at dplyr functions that allow you to create something new. Summarise() and mutate() are the two functions that allow you to do that: You can either create a complete new data.frame/tibble (summarise()) or by adding a new column to the existing data.frame you are working with (mutate()). Common data operations are calculating descriptive statistics like the average using mean(), the median (median()) or finding the minimum and the maximum of values (min() and max()). Have a look at the functions below. You will find many more and more information in the dyplr/summarise documentation or the mutate documentation.\nMost data operations are done on groups defined by variables. group_by() takes an existing data.frame and converts it into a grouped one where operations are performed “by group”.\n\n\n\n\n\n\n\nLet’s start with some basic summarising tasks, where we always create a simple dataframe as outcome. Using the penguins_data, let’s assume we want to solve the following questions/tasks:\n\nWhat is the average body_mass_g of the penguins?\nCount the number of different/unique islands the penguins were recorded.\nCreate a summary table (min,max,mean,median,IQR) for flipper_length_mm\n\n\n\nShow/Hide Code\n# Note the na.rm=TRUE argument for the mean - if one value is NA you need to remove it otherwise the outcome will be NA \npenguins_data%&gt;%summarise(avg=mean(body_mass_g,na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n    avg\n  &lt;dbl&gt;\n1 4202.\n\n\nShow/Hide Code\npenguins_data%&gt;%summarise(unique_islands = n_distinct(island))\n\n\n# A tibble: 1 × 1\n  unique_islands\n           &lt;int&gt;\n1              3\n\n\nShow/Hide Code\n# Summary table\n# Note that summary(flipper_length_mm) will give you all the information too\n# But we do it the dplyr way ... here more code but in the long run easier\n# Still it is not forbidden to use base r :)\n\n# How could we avoid having to write na.rm=TRUE so many times?\n\npenguins_data%&gt;%summarise(min_fl = min(flipper_length_mm,na.rm = TRUE),\n                          max_fl = max(flipper_length_mm,na.rm=TRUE),\n                          avg_fl = mean(flipper_length_mm,na.rm=TRUE),\n                          median_fl = median(flipper_length_mm,na.rm=TRUE),\n                          IQR_fl = IQR(flipper_length_mm,na.rm=TRUE))\n\n\n# A tibble: 1 × 5\n  min_fl max_fl avg_fl median_fl IQR_fl\n   &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1    172    231   201.       197     23\n\n\nNow it is on you again to perform some exercise with the usability_test_results:\n\nCount how many different countries the parcipants come from\nCalculate the average number of trips they do and how many countries they have visited\nCalculate the average and median task completion (tot_task*) for each task.\n\n\n\nRows: 30 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): participant_id, timestamp, age, gender, country_of_nationality, ed...\ndbl (11): trips_per_year, countries_visited, completion_task1, seq_task1, to...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nShow/Hide Code\nusability_test_results%&gt;%summarise(nunique_countries = n_distinct(country_of_nationality))\n\n\n# A tibble: 1 × 1\n  nunique_countries\n              &lt;int&gt;\n1                10\n\n\nShow/Hide Code\nusability_test_results%&gt;%\n              summarise(avg_trip = mean(trips_per_year),\n              avg_countries_vis = mean(countries_visited))\n\n\n# A tibble: 1 × 2\n  avg_trip avg_countries_vis\n     &lt;dbl&gt;             &lt;dbl&gt;\n1       NA                NA\n\n\nShow/Hide Code\nusability_test_results%&gt;%summarise(avg_tot_task1 = mean(tot_task1,na.rm=NA),\n                         median_tot_task1 = median(tot_task1,na.rm=TRUE))%&gt;%view()\n\n\n\n\n\nMost data operations are done on groups defined by variables. group_by() takes an existing data.frame and converts it into a grouped one where operations are performed “by group”. Using group_by() before summarise() creates a summary for each group. Each group has then a new row in the resulting data.frame. You can also find more information on what it means to group data in the tidyverse documentation.\nLet’s see group_by() in action in combination with summarise() by working on the following tasks: * What is the average weight for each penguin species and how many observations do we have? * How many penguins were found on each of the three different islands? * How many penguins from different species were found on each of the three different islands?\nA short version for group_by(...)%&gt;%summarise(n()) is count()\n\n\nShow/Hide Code\n# Let's have a look at group_by()\n\n# Calculate the average weight per species and how many penguins there are  \npenguins_data%&gt;%\n          group_by(species)%&gt;%\n              summarise(avg_weight=mean(body_mass_g,na.rm=TRUE),\n                                            count_penguins =n())\n\n\n# A tibble: 3 × 3\n  species   avg_weight count_penguins\n  &lt;fct&gt;          &lt;dbl&gt;          &lt;int&gt;\n1 Adelie         3701.            152\n2 Chinstrap      3733.             68\n3 Gentoo         5076.            124\n\n\nShow/Hide Code\n# Count how many penguins were found on the different islands \npenguins_data%&gt;%group_by(island)%&gt;%summarise(count_per_island = n())\n\n\n# A tibble: 3 × 2\n  island    count_per_island\n  &lt;fct&gt;                &lt;int&gt;\n1 Biscoe                 168\n2 Dream                  124\n3 Torgersen               52\n\n\nShow/Hide Code\n# group_by() can take multiple variables\npenguins_data%&gt;%group_by(species,island)%&gt;%summarise(count_island_species = n())\n\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   species [3]\n  species   island    count_island_species\n  &lt;fct&gt;     &lt;fct&gt;                    &lt;int&gt;\n1 Adelie    Biscoe                      44\n2 Adelie    Dream                       56\n3 Adelie    Torgersen                   52\n4 Chinstrap Dream                       68\n5 Gentoo    Biscoe                     124\n\n\nShow/Hide Code\n# count() is the shorter version of group_by() and summarise(n())\npenguins_data%&gt;%count(species,island)%&gt;%view()\n\n# We want to know the average body_weight_g for each species\npenguins_data%&gt;%group_by(species)%&gt;%summarise(avg_weight=mean(body_mass_g,na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  species   avg_weight\n  &lt;fct&gt;          &lt;dbl&gt;\n1 Adelie         3701.\n2 Chinstrap      3733.\n3 Gentoo         5076.\n\n\nNow it is again on you to perform some exercises with the usability_test_results: * How many participants are there for each education level? * Count how many participants per country_of_nationality there are * Calculate the average number of countries visited by gender * Calculate the number of participants per gender and country of nationality\n\n\nShow/Hide Code\n# Count how many participants per each education there are \nusability_test_results%&gt;%count(education,name=\"count_edu\")\n\n\n# A tibble: 5 × 2\n  education             count_edu\n  &lt;chr&gt;                     &lt;int&gt;\n1 Bachelor                     14\n2 College / Tradeschool         6\n3 Doctorate / PhD               1\n4 Highschool                    3\n5 Master                        6\n\n\nShow/Hide Code\nusability_test_results%&gt;%group_by(education)%&gt;%summarise(count_edu=n())\n\n\n# A tibble: 5 × 2\n  education             count_edu\n  &lt;chr&gt;                     &lt;int&gt;\n1 Bachelor                     14\n2 College / Tradeschool         6\n3 Doctorate / PhD               1\n4 Highschool                    3\n5 Master                        6\n\n\nShow/Hide Code\n# Count how many participants per country_of_nationality there are \nusability_test_results%&gt;%count(country_of_nationality)\n\n\n# A tibble: 10 × 2\n   country_of_nationality     n\n   &lt;chr&gt;                  &lt;int&gt;\n 1 Australia                  1\n 2 Austria                    1\n 3 Canada                     1\n 4 Denmark                    2\n 5 Germany                    1\n 6 Mexico                     2\n 7 Nepal                      1\n 8 Philippines                1\n 9 South Africa               1\n10 United States             19\n\n\nShow/Hide Code\n# Calculate the average number of countries visited by gender\nusability_test_results%&gt;%\n            group_by(gender)%&gt;%\n              summarise(avg_countries_visited=mean(countries_visited,na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  gender avg_countries_visited\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Female                  14.5\n2 Male                    18.2\n\n\nShow/Hide Code\n# Calculate the number of participants per gender and country of nationality \n#usability_test_results%&gt;%\n#  group_by(gender,country_of_nationality)%&gt;%mutate(gender_country_n=n())\n\nusability_test_results%&gt;%count(gender,country_of_nationality)\n\n\n# A tibble: 11 × 3\n   gender country_of_nationality     n\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;int&gt;\n 1 Female Austria                    1\n 2 Female Canada                     1\n 3 Female South Africa               1\n 4 Female United States              7\n 5 Male   Australia                  1\n 6 Male   Denmark                    2\n 7 Male   Germany                    1\n 8 Male   Mexico                     2\n 9 Male   Nepal                      1\n10 Male   Philippines                1\n11 Male   United States             12\n\n\n\n\n\nmutate() creates new columns that are functions of existing variables. It can also modify (if the name is the same as an existing column) existing columns. In the second case you just overwrite the original data, with the new data.\nHere are some examples with the penguins_data:\n\n\nShow/Hide Code\n# Let's finally look at mutate \n# which gives us the options to create new columns \n\npenguins_data%&gt;%\n               group_by(species)%&gt;%\n                  mutate(avg_weight = mean(body_mass_g,na.rm=TRUE))\n\n\n# A tibble: 344 × 9\n# Groups:   species [3]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, avg_weight &lt;dbl&gt;\n\n\nShow/Hide Code\npenguins_data%&gt;%\n              mutate(ratio_flipper_weight = flipper_length_mm/body_mass_g)%&gt;%view()\n\n\nTwo classic examples that you use mutate() for are: calculating percentage values and recode entries. Recoding often happens by using the case_when() helper function.\n\n\nShow/Hide Code\n# Example of common problem where you want percentages for a count data frame\n# First count then create a new percentage column with mutate\n\npenguins_data%&gt;%\n        count(species)%&gt;%\n          mutate(percentage = n/sum(n)*100)%&gt;%view()\n\n# This is the longer version\npenguins_data%&gt;%\n            group_by(species)%&gt;%\n              summarise(species_count =n())%&gt;%\n                mutate(total_sample = sum(species_count))%&gt;%\n                  mutate(percentage = species_count/total_sample)%&gt;%view()\n\n# Let's use the median to decide whether penguins are light or heavy\npenguins_data%&gt;%mutate(median_weight = median(body_mass_g,na.rm=TRUE))%&gt;%\n                  mutate(weight_category = case_when(\n                                          body_mass_g&lt;median_weight ~ 'light_penguin',\n                                          body_mass_g&gt;median_weight ~ 'heavy_penguin'))%&gt;%\n    select(species,weight_category)\n\n\n# A tibble: 344 × 2\n   species weight_category\n   &lt;fct&gt;   &lt;chr&gt;          \n 1 Adelie  light_penguin  \n 2 Adelie  light_penguin  \n 3 Adelie  light_penguin  \n 4 Adelie  &lt;NA&gt;           \n 5 Adelie  light_penguin  \n 6 Adelie  light_penguin  \n 7 Adelie  light_penguin  \n 8 Adelie  heavy_penguin  \n 9 Adelie  light_penguin  \n10 Adelie  heavy_penguin  \n# ℹ 334 more rows\n\n\nNow it is on you to perform some exercises. Perform the following tasks:\n\nTransform the tot_task1 from seconds to minutes\nCalculate the total time on tasks for each participant\nCalculate the average subjective difficulty for each participant\n\n\n\nShow/Hide Code\n# Transform the tot_task1 from seconds into minutes \nusability_test_results%&gt;%\n                  mutate(tot_task1_min=tot_task1/60)%&gt;%view()\n\n# Calculate the total time on task for each participant (tot_task1, 2, 3)\n\nusability_test_results%&gt;%\n                mutate(total_task_time = tot_task1+tot_task2+tot_task3)%&gt;%\n                  view()\n\n# avg subjective difficulty\nusability_test_results%&gt;%mutate(avg_sub_diff = (seq_task1+seq_task2+seq_task3)/3)%&gt;%view()"
  },
  {
    "objectID": "content/Session2.html#summarise",
    "href": "content/Session2.html#summarise",
    "title": "Part2:Collection, cleaning and transformation",
    "section": "",
    "text": "Let’s start with some basic summarising tasks, where we always create a simple dataframe as outcome. Using the penguins_data, let’s assume we want to solve the following questions/tasks:\n\nWhat is the average body_mass_g of the penguins?\nCount the number of different/unique islands the penguins were recorded.\nCreate a summary table (min,max,mean,median,IQR) for flipper_length_mm\n\n\n\nShow/Hide Code\n# Note the na.rm=TRUE argument for the mean - if one value is NA you need to remove it otherwise the outcome will be NA \npenguins_data%&gt;%summarise(avg=mean(body_mass_g,na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n    avg\n  &lt;dbl&gt;\n1 4202.\n\n\nShow/Hide Code\npenguins_data%&gt;%summarise(unique_islands = n_distinct(island))\n\n\n# A tibble: 1 × 1\n  unique_islands\n           &lt;int&gt;\n1              3\n\n\nShow/Hide Code\n# Summary table\n# Note that summary(flipper_length_mm) will give you all the information too\n# But we do it the dplyr way ... here more code but in the long run easier\n# Still it is not forbidden to use base r :)\n\n# How could we avoid having to write na.rm=TRUE so many times?\n\npenguins_data%&gt;%summarise(min_fl = min(flipper_length_mm,na.rm = TRUE),\n                          max_fl = max(flipper_length_mm,na.rm=TRUE),\n                          avg_fl = mean(flipper_length_mm,na.rm=TRUE),\n                          median_fl = median(flipper_length_mm,na.rm=TRUE),\n                          IQR_fl = IQR(flipper_length_mm,na.rm=TRUE))\n\n\n# A tibble: 1 × 5\n  min_fl max_fl avg_fl median_fl IQR_fl\n   &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1    172    231   201.       197     23\n\n\nNow it is on you again to perform some exercise with the usability_test_results:\n\nCount how many different countries the parcipants come from\nCalculate the average number of trips they do and how many countries they have visited\nCalculate the average and median task completion (tot_task*) for each task.\n\n\n\nRows: 30 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): participant_id, timestamp, age, gender, country_of_nationality, ed...\ndbl (11): trips_per_year, countries_visited, completion_task1, seq_task1, to...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nShow/Hide Code\nusability_test_results%&gt;%summarise(nunique_countries = n_distinct(country_of_nationality))\n\n\n# A tibble: 1 × 1\n  nunique_countries\n              &lt;int&gt;\n1                10\n\n\nShow/Hide Code\nusability_test_results%&gt;%\n              summarise(avg_trip = mean(trips_per_year),\n              avg_countries_vis = mean(countries_visited))\n\n\n# A tibble: 1 × 2\n  avg_trip avg_countries_vis\n     &lt;dbl&gt;             &lt;dbl&gt;\n1       NA                NA\n\n\nShow/Hide Code\nusability_test_results%&gt;%summarise(avg_tot_task1 = mean(tot_task1,na.rm=NA),\n                         median_tot_task1 = median(tot_task1,na.rm=TRUE))%&gt;%view()"
  },
  {
    "objectID": "content/Session2.html#group_by",
    "href": "content/Session2.html#group_by",
    "title": "Part2:Collection, cleaning and transformation",
    "section": "",
    "text": "Most data operations are done on groups defined by variables. group_by() takes an existing data.frame and converts it into a grouped one where operations are performed “by group”. Using group_by() before summarise() creates a summary for each group. Each group has then a new row in the resulting data.frame. You can also find more information on what it means to group data in the tidyverse documentation.\nLet’s see group_by() in action in combination with summarise() by working on the following tasks: * What is the average weight for each penguin species and how many observations do we have? * How many penguins were found on each of the three different islands? * How many penguins from different species were found on each of the three different islands?\nA short version for group_by(...)%&gt;%summarise(n()) is count()\n\n\nShow/Hide Code\n# Let's have a look at group_by()\n\n# Calculate the average weight per species and how many penguins there are  \npenguins_data%&gt;%\n          group_by(species)%&gt;%\n              summarise(avg_weight=mean(body_mass_g,na.rm=TRUE),\n                                            count_penguins =n())\n\n\n# A tibble: 3 × 3\n  species   avg_weight count_penguins\n  &lt;fct&gt;          &lt;dbl&gt;          &lt;int&gt;\n1 Adelie         3701.            152\n2 Chinstrap      3733.             68\n3 Gentoo         5076.            124\n\n\nShow/Hide Code\n# Count how many penguins were found on the different islands \npenguins_data%&gt;%group_by(island)%&gt;%summarise(count_per_island = n())\n\n\n# A tibble: 3 × 2\n  island    count_per_island\n  &lt;fct&gt;                &lt;int&gt;\n1 Biscoe                 168\n2 Dream                  124\n3 Torgersen               52\n\n\nShow/Hide Code\n# group_by() can take multiple variables\npenguins_data%&gt;%group_by(species,island)%&gt;%summarise(count_island_species = n())\n\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   species [3]\n  species   island    count_island_species\n  &lt;fct&gt;     &lt;fct&gt;                    &lt;int&gt;\n1 Adelie    Biscoe                      44\n2 Adelie    Dream                       56\n3 Adelie    Torgersen                   52\n4 Chinstrap Dream                       68\n5 Gentoo    Biscoe                     124\n\n\nShow/Hide Code\n# count() is the shorter version of group_by() and summarise(n())\npenguins_data%&gt;%count(species,island)%&gt;%view()\n\n# We want to know the average body_weight_g for each species\npenguins_data%&gt;%group_by(species)%&gt;%summarise(avg_weight=mean(body_mass_g,na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  species   avg_weight\n  &lt;fct&gt;          &lt;dbl&gt;\n1 Adelie         3701.\n2 Chinstrap      3733.\n3 Gentoo         5076.\n\n\nNow it is again on you to perform some exercises with the usability_test_results: * How many participants are there for each education level? * Count how many participants per country_of_nationality there are * Calculate the average number of countries visited by gender * Calculate the number of participants per gender and country of nationality\n\n\nShow/Hide Code\n# Count how many participants per each education there are \nusability_test_results%&gt;%count(education,name=\"count_edu\")\n\n\n# A tibble: 5 × 2\n  education             count_edu\n  &lt;chr&gt;                     &lt;int&gt;\n1 Bachelor                     14\n2 College / Tradeschool         6\n3 Doctorate / PhD               1\n4 Highschool                    3\n5 Master                        6\n\n\nShow/Hide Code\nusability_test_results%&gt;%group_by(education)%&gt;%summarise(count_edu=n())\n\n\n# A tibble: 5 × 2\n  education             count_edu\n  &lt;chr&gt;                     &lt;int&gt;\n1 Bachelor                     14\n2 College / Tradeschool         6\n3 Doctorate / PhD               1\n4 Highschool                    3\n5 Master                        6\n\n\nShow/Hide Code\n# Count how many participants per country_of_nationality there are \nusability_test_results%&gt;%count(country_of_nationality)\n\n\n# A tibble: 10 × 2\n   country_of_nationality     n\n   &lt;chr&gt;                  &lt;int&gt;\n 1 Australia                  1\n 2 Austria                    1\n 3 Canada                     1\n 4 Denmark                    2\n 5 Germany                    1\n 6 Mexico                     2\n 7 Nepal                      1\n 8 Philippines                1\n 9 South Africa               1\n10 United States             19\n\n\nShow/Hide Code\n# Calculate the average number of countries visited by gender\nusability_test_results%&gt;%\n            group_by(gender)%&gt;%\n              summarise(avg_countries_visited=mean(countries_visited,na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  gender avg_countries_visited\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Female                  14.5\n2 Male                    18.2\n\n\nShow/Hide Code\n# Calculate the number of participants per gender and country of nationality \n#usability_test_results%&gt;%\n#  group_by(gender,country_of_nationality)%&gt;%mutate(gender_country_n=n())\n\nusability_test_results%&gt;%count(gender,country_of_nationality)\n\n\n# A tibble: 11 × 3\n   gender country_of_nationality     n\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;int&gt;\n 1 Female Austria                    1\n 2 Female Canada                     1\n 3 Female South Africa               1\n 4 Female United States              7\n 5 Male   Australia                  1\n 6 Male   Denmark                    2\n 7 Male   Germany                    1\n 8 Male   Mexico                     2\n 9 Male   Nepal                      1\n10 Male   Philippines                1\n11 Male   United States             12"
  },
  {
    "objectID": "content/Session2.html#mutate",
    "href": "content/Session2.html#mutate",
    "title": "Part2:Collection, cleaning and transformation",
    "section": "",
    "text": "mutate() creates new columns that are functions of existing variables. It can also modify (if the name is the same as an existing column) existing columns. In the second case you just overwrite the original data, with the new data.\nHere are some examples with the penguins_data:\n\n\nShow/Hide Code\n# Let's finally look at mutate \n# which gives us the options to create new columns \n\npenguins_data%&gt;%\n               group_by(species)%&gt;%\n                  mutate(avg_weight = mean(body_mass_g,na.rm=TRUE))\n\n\n# A tibble: 344 × 9\n# Groups:   species [3]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, avg_weight &lt;dbl&gt;\n\n\nShow/Hide Code\npenguins_data%&gt;%\n              mutate(ratio_flipper_weight = flipper_length_mm/body_mass_g)%&gt;%view()\n\n\nTwo classic examples that you use mutate() for are: calculating percentage values and recode entries. Recoding often happens by using the case_when() helper function.\n\n\nShow/Hide Code\n# Example of common problem where you want percentages for a count data frame\n# First count then create a new percentage column with mutate\n\npenguins_data%&gt;%\n        count(species)%&gt;%\n          mutate(percentage = n/sum(n)*100)%&gt;%view()\n\n# This is the longer version\npenguins_data%&gt;%\n            group_by(species)%&gt;%\n              summarise(species_count =n())%&gt;%\n                mutate(total_sample = sum(species_count))%&gt;%\n                  mutate(percentage = species_count/total_sample)%&gt;%view()\n\n# Let's use the median to decide whether penguins are light or heavy\npenguins_data%&gt;%mutate(median_weight = median(body_mass_g,na.rm=TRUE))%&gt;%\n                  mutate(weight_category = case_when(\n                                          body_mass_g&lt;median_weight ~ 'light_penguin',\n                                          body_mass_g&gt;median_weight ~ 'heavy_penguin'))%&gt;%\n    select(species,weight_category)\n\n\n# A tibble: 344 × 2\n   species weight_category\n   &lt;fct&gt;   &lt;chr&gt;          \n 1 Adelie  light_penguin  \n 2 Adelie  light_penguin  \n 3 Adelie  light_penguin  \n 4 Adelie  &lt;NA&gt;           \n 5 Adelie  light_penguin  \n 6 Adelie  light_penguin  \n 7 Adelie  light_penguin  \n 8 Adelie  heavy_penguin  \n 9 Adelie  light_penguin  \n10 Adelie  heavy_penguin  \n# ℹ 334 more rows\n\n\nNow it is on you to perform some exercises. Perform the following tasks:\n\nTransform the tot_task1 from seconds to minutes\nCalculate the total time on tasks for each participant\nCalculate the average subjective difficulty for each participant\n\n\n\nShow/Hide Code\n# Transform the tot_task1 from seconds into minutes \nusability_test_results%&gt;%\n                  mutate(tot_task1_min=tot_task1/60)%&gt;%view()\n\n# Calculate the total time on task for each participant (tot_task1, 2, 3)\n\nusability_test_results%&gt;%\n                mutate(total_task_time = tot_task1+tot_task2+tot_task3)%&gt;%\n                  view()\n\n# avg subjective difficulty\nusability_test_results%&gt;%mutate(avg_sub_diff = (seq_task1+seq_task2+seq_task3)/3)%&gt;%view()"
  },
  {
    "objectID": "content/Session2.html#the-relig_income-case",
    "href": "content/Session2.html#the-relig_income-case",
    "title": "Part2:Collection, cleaning and transformation",
    "section": "The relig_income case",
    "text": "The relig_income case\n\n\nShow/Hide Code\n# relig_income:column headers are values not variable names-&gt;we need to make a wide data.frame longer\n\n# relig_income is messy / not tidy ... how can we make it tidy?\nrelig_income&lt;-relig_income\n\nrelig_income%&gt;%pivot_longer(cols=2:11,\n                              names_to = 'income_range',\n                                  values_to ='count')\n\n\n# A tibble: 180 × 3\n   religion income_range       count\n   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;\n 1 Agnostic &lt;$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic &gt;150k                 84\n10 Agnostic Don't know/refused    96\n# ℹ 170 more rows\n\n\nShow/Hide Code\n# Now one could count the total per religious belief \nrelig_income%&gt;%pivot_longer(cols=2:11,\n                              names_to = 'income_range',\n                                  values_to ='count')%&gt;%group_by(religion)%&gt;%summarise(total_part=sum(count))%&gt;%view()"
  },
  {
    "objectID": "content/Session2.html#the-us_rent_income-case",
    "href": "content/Session2.html#the-us_rent_income-case",
    "title": "Part2:Collection, cleaning and transformation",
    "section": "The us_rent_income case",
    "text": "The us_rent_income case\n\n\nShow/Hide Code\n#us_rent_income:one observation over multiple rows - &gt;we need to make a long data.frame wider\n\nus_rent_income&lt;-us_rent_income\n\nus_rent_income%&gt;%pivot_wider(names_from = variable,\n                                  values_from = c('estimate','moe'))%&gt;%view()"
  },
  {
    "objectID": "content/Session3.html",
    "href": "content/Session3.html",
    "title": "Data collection:crawling social media (Reddit)",
    "section": "",
    "text": "Social media data plays an important role in many disciplines outside and inside academia ranging from marketing to computational social science or digital methods. Unfortunately, the last couple of years have seen the rise of the post-API (application programming interface) era, in which it is getting more and more challenging to get programmatic and legal access to data from social media platforms like Facebook, Instagram or X (Twitter). Reddit remains (with limitations) the only platform where API access is still available.\n\n\nRedditExtractorR is an R package for extracting data out of Reddit. It allows you to:\n\nfind subreddits based on a search query (find_subrredits())\nfind a user and their Reddit history (get_user_content())\nfind URLs to threads/posts (find_thread_urls()) of interest and retrieve comments out of these threads/posts (get_thread_content())\n\n\n\nFor this session, you will have to install the two packages RedditExtractoR and tidytext. While we collect some Reddit posts we will perform some very basic text mining using tidytext.\n\n\nShow/Hide Code\ninstall.packages(\"RedditExtractoR\")\ninstall.packages(\"tidytext\")\nrequire(RedditExtractoR)\nrequire(tidytext)\nrequire(tidyverse)\n\n\n\n\n\n\nThe subrredit r/Dreams is a community of redditors that share their dreams, discuss their meaning and ask for interpretation. Data from this subreddit has, for example, been used in a study by Fogli et al. (2020) where they try to investigate the ‘continuity hypothesis’ meaning that dreams are a continuation of what happens in everyday life.\n\n\nShow/Hide Code\n# We extract posts from the subreddit r/Dreams\nr_dreams&lt;-find_thread_urls(subreddit = 'Dreams')\n\n# Let's see what the average number of posts per day is\nr_dreams%&gt;%count(date_utc)%&gt;%\n  summarise(mean_n_posts_day = \n              mean(n,na.rm=TRUE))%&gt;%view()\n\n# Let's compare different ways of setting the time parameter\nr_dreams_week&lt;-find_thread_urls(subreddit = 'Dreams',\n                                period = 'week')\n\nr_dreams_all&lt;-find_thread_urls(subreddit = 'Dreams',\n                               period = 'all')\n\n# How many comments do posts on average receive?\nr_dreams_all%&gt;%summarise(avg_comment_count = mean(comments,na.rm=TRUE))\n\n\nNote that the function find_thread_urls() has two parameters sort_by and period. Per default we get sort_by=top posts per period = month.\nBesides of looking at threads/posts alone, we can also get all comments that a post received. For this we can pass one or multiple URLs (i.e. links to posts) into the function get_thread_content(). The outcome is a list with two elements. One of these elements is a dataframe that contains all comments.\n\n\nShow/Hide Code\n# We can extract all comments for a certain post\nextract_comments&lt;-get_thread_content(urls = 'https://www.reddit.com/r/Dreams/comments/l7rlpb/i_had_a_dream_i_was_attending_a_geometry_class/')\n\n# Remember that the outcome is a list with two dataframes\n# We want the second data frame called comments\npost_comments&lt;-extract_comments$comments\n\n# extracting one column from a data frame can be done\n# with dollar notation r_dreams_all$url\n# or the pull function from dplyr  \n\nget_all_comments&lt;-get_thread_content(urls = r_dreams_all%&gt;%pull('url'))\n\n# We use the unnest_tokens function \n#to get the count of the words                    \nr_dreams_all%&gt;%\n  unnest_tokens(input = title,\n                output = word)%&gt;%count(word,sort=TRUE)\n\n\n\n\n\n\nCollect some threads from the subrreddit r/haiku. What are the most frequent words that appear in the poems?\nUse the function to extract all posts from user u/mvea\n\n\n\nShow/Hide Code\nr_haiku_all&lt;-find_thread_urls(subreddit = 'haiku',\n                               period = 'all')\n\nuser_mvea&lt;-get_user_content(users = 'mvea')"
  },
  {
    "objectID": "content/Session3.html#redditextractor",
    "href": "content/Session3.html#redditextractor",
    "title": "Data collection:crawling social media (Reddit)",
    "section": "",
    "text": "RedditExtractorR is an R package for extracting data out of Reddit. It allows you to:\n\nfind subreddits based on a search query (find_subrredits())\nfind a user and their Reddit history (get_user_content())\nfind URLs to threads/posts (find_thread_urls()) of interest and retrieve comments out of these threads/posts (get_thread_content())\n\n\n\nFor this session, you will have to install the two packages RedditExtractoR and tidytext. While we collect some Reddit posts we will perform some very basic text mining using tidytext.\n\n\nShow/Hide Code\ninstall.packages(\"RedditExtractoR\")\ninstall.packages(\"tidytext\")\nrequire(RedditExtractoR)\nrequire(tidytext)\nrequire(tidyverse)"
  },
  {
    "objectID": "content/Session3.html#show-and-tell-with-rdreams",
    "href": "content/Session3.html#show-and-tell-with-rdreams",
    "title": "Data collection:crawling social media (Reddit)",
    "section": "",
    "text": "The subrredit r/Dreams is a community of redditors that share their dreams, discuss their meaning and ask for interpretation. Data from this subreddit has, for example, been used in a study by Fogli et al. (2020) where they try to investigate the ‘continuity hypothesis’ meaning that dreams are a continuation of what happens in everyday life.\n\n\nShow/Hide Code\n# We extract posts from the subreddit r/Dreams\nr_dreams&lt;-find_thread_urls(subreddit = 'Dreams')\n\n# Let's see what the average number of posts per day is\nr_dreams%&gt;%count(date_utc)%&gt;%\n  summarise(mean_n_posts_day = \n              mean(n,na.rm=TRUE))%&gt;%view()\n\n# Let's compare different ways of setting the time parameter\nr_dreams_week&lt;-find_thread_urls(subreddit = 'Dreams',\n                                period = 'week')\n\nr_dreams_all&lt;-find_thread_urls(subreddit = 'Dreams',\n                               period = 'all')\n\n# How many comments do posts on average receive?\nr_dreams_all%&gt;%summarise(avg_comment_count = mean(comments,na.rm=TRUE))\n\n\nNote that the function find_thread_urls() has two parameters sort_by and period. Per default we get sort_by=top posts per period = month.\nBesides of looking at threads/posts alone, we can also get all comments that a post received. For this we can pass one or multiple URLs (i.e. links to posts) into the function get_thread_content(). The outcome is a list with two elements. One of these elements is a dataframe that contains all comments.\n\n\nShow/Hide Code\n# We can extract all comments for a certain post\nextract_comments&lt;-get_thread_content(urls = 'https://www.reddit.com/r/Dreams/comments/l7rlpb/i_had_a_dream_i_was_attending_a_geometry_class/')\n\n# Remember that the outcome is a list with two dataframes\n# We want the second data frame called comments\npost_comments&lt;-extract_comments$comments\n\n# extracting one column from a data frame can be done\n# with dollar notation r_dreams_all$url\n# or the pull function from dplyr  \n\nget_all_comments&lt;-get_thread_content(urls = r_dreams_all%&gt;%pull('url'))\n\n# We use the unnest_tokens function \n#to get the count of the words                    \nr_dreams_all%&gt;%\n  unnest_tokens(input = title,\n                output = word)%&gt;%count(word,sort=TRUE)"
  },
  {
    "objectID": "content/Session3.html#exercise",
    "href": "content/Session3.html#exercise",
    "title": "Data collection:crawling social media (Reddit)",
    "section": "",
    "text": "Collect some threads from the subrreddit r/haiku. What are the most frequent words that appear in the poems?\nUse the function to extract all posts from user u/mvea\n\n\n\nShow/Hide Code\nr_haiku_all&lt;-find_thread_urls(subreddit = 'haiku',\n                               period = 'all')\n\nuser_mvea&lt;-get_user_content(users = 'mvea')"
  },
  {
    "objectID": "content/Session4.html",
    "href": "content/Session4.html",
    "title": "Data analysis:descriptive statistics & visualisation",
    "section": "",
    "text": "Descriptive statistics provide simple summaries about the sample and about the observations that have been made. Such summaries may be either quantitative, i.e. summary statistics, or visual, i.e. simple-to-understand graphs. These summaries may either form the basis of the initial description of the data as part of a more extensive statistical analysis, or they may be sufficient in and of themselves for a particular investigation. As the average is self-explanatory and well understood we won’t go into details here. However, it is interesting to look at the relation between median and the average.\nFor all the examples here we will be using the tidyverse and the palmer penguins package. Exercises that I will prompt you to perform on your own will be done with the usability_test_results.csv data.\n\n\nShow/Hide Code\nrequire(tidyverse)\nrequire(palmerpenguins)\n\npenguins_data&lt;-penguins\n\nusability_test_results &lt;- read_csv(\"usability_test_results.csv\")\n\n\n\n\nThe median is calculated by first sorting a variable’s data from smallest to largest. After sorting the data, the middle element in the list is the median. If the middle falls between two values, then the median is the mean of those two middle values.\n\n\n\nThe standard deviation (SD) is a measure of how far we expect a given data value will be from its mean (variation, dispersion of data). A high SD means the data is spread out, while a low SD indicates that the values are close together.\n\n\n\nThe five point summary uses the following five values: (1) the minimum, (2) the first quantile AKA 25th percentile, (3) the second quantile AKA median or 50th percentile, (4) the third quantile AKA 75th, and (5) the maximum. The five-number summary of a variable is used when constructing boxplots. The quantiles are calculated as:\n\nFirst quantile (Q1): the median of the first half of the sorted data\nThird quantile (Q3): the median of the second half of the sorted data\n\nThe interquartile range (IQR) is defined as Q3−Q1 and is a measure of how spread out the middle 50% of values are. The IQR corresponds to the length of the box in a boxplot.  Median and IQR are not influecned by outliers in the ways mean and SD are and are thus recommended for skewed datasets . Correlation can be calculated using the function cor(x, y, method = c(\"pearson\", \"kendall\", \"spearman\")).\nShow and tell with palmer penguins:\n\nCalculating the median and SD of flipper_length_mm.\nCalculating the five-point summary for body_mass_g.\nCalculating the correlation between bill_length_mm and bill_depth_mm.\n\n\n\nShow/Hide Code\npenguins_data%&gt;%summarise(median_fl_mm = median(flipper_length_mm,na.rm=TRUE),\n                          sd_fl_mm = sd(flipper_length_mm,na.rm=TRUE))\n\n\n# A tibble: 1 × 2\n  median_fl_mm sd_fl_mm\n         &lt;dbl&gt;    &lt;dbl&gt;\n1          197     14.1\n\n\nShow/Hide Code\n#Of course this is most interesting per species\npenguins_data%&gt;%group_by(species)%&gt;%\n          summarise(median_fl_mm = median(flipper_length_mm,na.rm=TRUE),\n                    sd_fl_mm = sd(flipper_length_mm,na.rm=TRUE))\n\n\n# A tibble: 3 × 3\n  species   median_fl_mm sd_fl_mm\n  &lt;fct&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n1 Adelie             190     6.54\n2 Chinstrap          196     7.13\n3 Gentoo             216     6.48\n\n\nShow/Hide Code\n# 5 point summary easily achieved like this\nsummary(penguins_data$body_mass_g)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n\nShow/Hide Code\n# Something new cor()\n# How can we interpret the output?\npenguins_data%&gt;%summarise(correlation = cor(bill_length_mm,bill_depth_mm,use='complete.obs'))\n\n\n# A tibble: 1 × 1\n  correlation\n        &lt;dbl&gt;\n1      -0.235\n\n\nTry it for yourself: * Calculate the correlation between time (tot_task1) and preceived difficulty (seq_task_1)\n\n\nShow/Hide Code\ncor(usability_test_results$tot_task1,usability_test_results$seq_task1) \n\n\n[1] -0.006825935"
  },
  {
    "objectID": "content/Session4.html#scatterplots",
    "href": "content/Session4.html#scatterplots",
    "title": "Data analysis:descriptive statistics & visualisation",
    "section": "Scatterplots",
    "text": "Scatterplots\nScatterplots are one of the most common ways to plot to numeric/continous variables on x and y. We create a scatter plot (geom_point()) of bill_length_mm and bill_depth_mm. We can make addtional modifications to the plot:\n\nWe map species on color\nWe can set the aesthetic (by turning all points green, happens outside of aes())\nWe can try to add yet another variable and map body_mass_g on size\nWe can make the dots transparent (alpha)\nWe can use double enconding (recommended practice!) by mapping species also on shape\nWe can add a regression line (geom_smooth()).\n\n\n\nShow/Hide Code\n# This is a way of doing double-enconding mapping species\n# both on color and on shape \n\nggplot(data=penguins_data,\n    mapping=aes(x=bill_length_mm,y=bill_depth_mm,\n                    color=species,shape=species,size=body_mass_g))+\n                      geom_point(alpha=0.5)\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nShow/Hide Code\n# Lets add a regression line (for visual aid for the eye)\nggplot(data=penguins_data,\n       mapping=aes(x=bill_length_mm,y=bill_depth_mm))+\n          geom_point(alpha=0.5,aes(color=species,\n              shape=species))+geom_smooth(method = 'lm')\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nTry it for yourself using usability_test_results.csv:\n\nCreate a scatterplot of trips_per_year and countries_visited.\n\nMap gender on color\nWe set the shape to be a diamond (look it up in the documentation)\n\nCreate a scatterplot of tot_task1 and seq_task1.\n\nMap gender on color # Add a regression line\n\n\n\n\nShow/Hide Code\nusability_test_results%&gt;%\n    # do all sorts of manipulation here before plotting) %&gt;%\n    ggplot(aes(x=trips_per_year,y=countries_visited,\n               color=gender))+geom_point(shape=18,size=5)\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nShow/Hide Code\nusability_test_results%&gt;%\n        ggplot(aes(x=tot_task1,y=seq_task1))+\n          geom_point(aes(color=gender))+geom_smooth(method='lm')\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/Session4.html#bar-charts",
    "href": "content/Session4.html#bar-charts",
    "title": "Data analysis:descriptive statistics & visualisation",
    "section": "Bar charts",
    "text": "Bar charts\nBar charts work well for simple counts and percentages. We often want to show how some group, entity, or amount breaks down into individual pieces that each represent a proportion of the whole. Common examples include the proportions of men and women in a group of people, the percentages of people voting for different political parties in an election, or the market shares of companies. ggplot has two geom functions for bar charts: geom_bar() where the counting is done automatically and geom_col().\n\n\nShow/Hide Code\npenguins_data%&gt;%\n  ggplot(aes(y=species,fill=island))+geom_bar()\n\n\n\n\n\nShow/Hide Code\npenguins_data%&gt;%\n  group_by(species)%&gt;%\n    summarise(penguin_count = n())%&gt;%\n      ggplot(aes(x=species,y=penguin_count,fill=species))+\n          geom_col(position=position_dodge())\n\n\n\n\n\nShow/Hide Code\n# Let's do a percentage plot \npenguins_data%&gt;%\n  group_by(island,species)%&gt;%\n  summarise(penguin_count = n())%&gt;%ungroup()%&gt;%\n    mutate(percentage = penguin_count/sum(penguin_count))%&gt;%\n      ggplot(aes(x=island,y=percentage,fill=species))+\n          geom_col()\n\n\n`summarise()` has grouped output by 'island'. You can override using the\n`.groups` argument.\n\n\n\n\n\nTry it for yourself using usability_test_results.csv:\n\nFor showing participants demographics, create a bar chart of:\n\nThe age groups\nThe education\nFavourite country by gender\nA way to improve bar chart visualisations is creating small multiples. For this we can use the function facet_wrap(). Have a look in the documentation on how to use it.\n\n\n\n\nShow/Hide Code\n# Some exercise with the usability_test_data\n# Create a bar chart from the age groups\nusability_test_results%&gt;%\n  ggplot(aes(x=age))+geom_bar()\n\n\n\n\n\nShow/Hide Code\n# Create a bar chart for the variable education\nusability_test_results%&gt;%\n  ggplot(aes(x=education))+geom_bar()\n\n\n\n\n\nShow/Hide Code\n# Create a bar chart that shows favorite country by gender \nusability_test_results%&gt;%\n  filter(!is.na(favority_country))%&gt;%\n  ggplot(aes(y=favority_country,fill=gender))+geom_bar()\n\n\n\n\n\nShow/Hide Code\n# Now here an example for facet_wrap()\nusability_test_results%&gt;%\n  filter(!is.na(favority_country))%&gt;%\n  ggplot(aes(y=favority_country,fill=gender))+geom_bar()+facet_wrap(vars(gender))\n\n\n\n\n\nShow/Hide Code\n#scales = 'free')"
  },
  {
    "objectID": "content/Session4.html#histograms-and-boxplots",
    "href": "content/Session4.html#histograms-and-boxplots",
    "title": "Data analysis:descriptive statistics & visualisation",
    "section": "Histograms and boxplots",
    "text": "Histograms and boxplots\nHistograms and boxplots are two common means to visualise distributions. The distribution of a variable shows how frequently different values of a variable occur. Looking at the visualization of a distribution can show where the values are centered, show how the values vary, and give some information about where a typical value might fall. It can also alert you to the presence of outliers."
  },
  {
    "objectID": "content/Session4.html#scatter-plots",
    "href": "content/Session4.html#scatter-plots",
    "title": "Data analysis:descriptive statistics & visualisation",
    "section": "Scatter plots",
    "text": "Scatter plots\nScatterplots are one of the most common ways to plot two numeric/continous variables on x and y to show their association. We create a scatter plot (geom_point()) of bill_length_mm and bill_depth_mm. We can make additional modifications to the plot:\n\nWe map species on color\nWe can set the aesthetic (by turning all points green, happens outside of aes())\nWe can try to add yet another variable and map body_mass_g on size\nWe can make the dots transparent (alpha)\nWe can use double encoding (recommended practice!) by mapping species on shape too\nWe can add a regression line (geom_smooth()).\n\n\n\nShow/Hide Code\n# This is a way of doing double-enconding mapping species\n# both on color and on shape \n\nggplot(data=penguins_data,\n    mapping=aes(x=bill_length_mm,y=bill_depth_mm,\n                    color=species,shape=species,size=body_mass_g))+\n                      geom_point(alpha=0.5)\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nShow/Hide Code\n# Lets add a regression line (for visual aid for the eye)\nggplot(data=penguins_data,\n       mapping=aes(x=bill_length_mm,y=bill_depth_mm))+\n          geom_point(alpha=0.5,aes(color=species,\n              shape=species))+geom_smooth(method = 'lm')\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nTry it for yourself using usability_test_results.csv:\n\nCreate a scatterplot of trips_per_year and countries_visited.\n\nMap gender on color\nWe set the shape to be a diamond (look it up in the documentation)\n\nCreate a scatterplot of tot_task1 and seq_task1.\n\nMap gender on color\nAdd a regression line\n\n\n\n\nShow/Hide Code\nusability_test_results%&gt;%\n    # do all sorts of manipulation here before plotting) %&gt;%\n    ggplot(aes(x=trips_per_year,y=countries_visited,\n               color=gender))+geom_point(shape=18,size=5)\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nShow/Hide Code\nusability_test_results%&gt;%\n        ggplot(aes(x=tot_task1,y=seq_task1))+\n          geom_point(aes(color=gender))+geom_smooth(method='lm')\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/Session4.html#histograms-boxplots-and-density-plots",
    "href": "content/Session4.html#histograms-boxplots-and-density-plots",
    "title": "Data analysis:descriptive statistics & visualisation",
    "section": "Histograms, boxplots and density plots",
    "text": "Histograms, boxplots and density plots\nHistograms, boxplots and density plots are three common means to visualize distributions. The distribution of a variable shows how frequently different values of a variable occur. Looking at the visualization of a distribution can show where the values are centered, show how the values vary, and give some information about where a typical value might fall. It can also alert you to the presence of outliers.\nLet’s look at an exmaple with the penguins: * We create a boxplot of body_mass_g, we can add points on top of it, but we choose geom_jitter() over geom_points() which adds a bit of noise. * We set the width=0.2 to spread out the points a bit, and alpha=0.6 so we account for the overlapping. * We map species on to color * We create a second graph to show the distribution with geom_density()\n\n\nShow/Hide Code\n#guides(color='none') removes the color legend\npenguins_data%&gt;%\n  ggplot(aes(x=body_mass_g,y=species,color=species))+geom_boxplot()+\n      geom_jitter(height=0.2,alpha=0.4)+theme_minimal()+guides(color='none')\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nTry it yourself with usability_test_results.csv:\n\nCreate a histogram and density plot of trips_per_year\nCreate a boxplot of all time_on_task columns.Hint: We need to transform the data from wide to long format so all tot_task variables are in the same column.\n\n\n\nShow/Hide Code\nusability_test_results%&gt;%\n      select(tot_task1,tot_task2,tot_task3)%&gt;%\n          pivot_longer(cols=everything(),\n                        names_to = 'task',\n                          values_to = 'time_on_task')%&gt;%\nggplot(aes(x=task,y=time_on_task,color=task))+geom_boxplot()"
  },
  {
    "objectID": "content/Session4.html#good-practices-in-data-viz",
    "href": "content/Session4.html#good-practices-in-data-viz",
    "title": "Data analysis:descriptive statistics & visualisation",
    "section": "Good practices in data viz",
    "text": "Good practices in data viz\nWhen teaching data visualisation (even in the simplest sense) it is important to discussgood practices, e.g. present data in ascending/descending order, label axes in a way that matches your narrative, etc. Packages like scales and forcats are incredibly helpful for implementing these small but impactful improvements to visualisations. In this example we improve the standard plot by:\n\nSorting the bars in an descending order\nCreate meaningful labels for the ticks (%-sign)\nAdd appropriate X,Y and title labels\n\n\n\nShow/Hide Code\n#install.packages('scales')\nrequire(scales)\n\n\nLoading required package: scales\n\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nShow/Hide Code\npenguins %&gt;%\n  count(species) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ggplot(aes(x = prop, y = fct_reorder(species, prop))) +\n  geom_col() +\n  scale_x_continuous(labels = label_percent(accuracy = 1)) +\n  labs(\n    x = \"Percentage\",\n    y = \"Species\",\n    title = \"Species distribution of penguins\",\n    subtitle = \"Adelie, Gentoo, and Chinstrap Penguins at Palmer Station\",\n  )\n\n\n\n\n\nThink about users that have some form of color-vision deficiency. It is recommended to use cvd-safe color scales. One of these is the Okabe-Ito scale (qualitative). For other purposes (continous scales) viridis is a good choice.\n\n\nShow/Hide Code\ncolor_values &lt;-c('#E69F00','#56B4E9','#009E73')\n\n\nggplot(data=penguins_data,\n    mapping=aes(x=bill_length_mm,y=bill_depth_mm,\n                    color=species,shape=species))+\n                      geom_point(alpha=0.7)+\n    scale_color_manual(values = color_values)+\n      labs(x='Bill Length',y='Bill Depth',color='Species',shape='Species')+\n      theme_bw(base_size = 16)+theme(legend.position = 'top')\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  }
]